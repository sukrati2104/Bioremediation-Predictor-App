# -*- coding: utf-8 -*-
"""Bioremediation Predictor App

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1PBjPz0ZiTxkoxnIlIk3ikp1oOjoUCe0q
"""

import streamlit as st
import pandas as pd
import numpy as np
import joblib
import json
import os
from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier
from sklearn.preprocessing import LabelEncoder

# --- 1. Constants and Configuration ---
# Filepaths for assets (must match the files in the same GitHub repository)
SCALER_FILE = "scaler.pkl"
REGRESSION_MODEL_FILE = "rf_regressor_model.pkl"
CLASSIFICATION_MODEL_FILE = "rf_classifier_model.pkl"
LE_MAP_FILE = "LE_MAP.json" # New file for label encoding map

# Define the feature list and column types (Crucial for model prediction order)
FEATURE_COLS = ['Site', 'Metal', 'Microbe_Used', 'Source', 'Initial_pH', 'Temperature_C',
                'Concentration_mg_L', 'Contact_Time_hours', 'Microbe_Dose_mg_L',
                'Latitude', 'Longitude']
NUMERIC_COLS = ['Initial_pH', 'Temperature_C', 'Concentration_mg_L',
                'Contact_Time_hours', 'Microbe_Dose_mg_L', 'Latitude', 'Longitude']
CATEGORICAL_COLS = ['Site', 'Metal', 'Microbe_Used', 'Source']

# --- 2. Loading Saved Assets ---
@st.cache_resource
def load_assets():
    """Loads the scaler, trained models, and Label Encoding Map."""

    # 2.1 Load Label Encoding Map (Essential for categorical input)
    if not os.path.exists(LE_MAP_FILE):
        st.error(f"FATAL ERROR: Missing file: {LE_MAP_FILE}. Please create and upload it as instructed.")
        st.stop()
    try:
        with open(LE_MAP_FILE, 'r') as f:
            le_map = json.load(f)
    except Exception as e:
        st.error(f"Error loading {LE_MAP_FILE}: {e}. Check JSON format.")
        st.stop()

    # 2.2 Load Scaler, Regression, and Classification Models
    # Use st.cache_resource to avoid reloading on every interaction
    try:
        scaler = joblib.load(SCALER_FILE)
        reg_model = joblib.load(REGRESSION_MODEL_FILE)
        clf_model = joblib.load(CLASSIFICATION_MODEL_FILE)

        # Extract categorical options for Streamlit select boxes from the loaded map
        cat_options = {col: list(le_map[col].keys()) for col in CATEGORICAL_COLS}

    except Exception as e:
        st.error(f"FATAL ERROR: Could not load model/scaler files. Ensure these three files are present: {SCALER_FILE}, {REGRESSION_MODEL_FILE}, {CLASSIFICATION_MODEL_FILE}. Error: {e}")
        st.stop()

    return scaler, reg_model, clf_model, le_map, cat_options

# Load all assets globally
scaler, reg_model, clf_model, LE_MAP, CAT_OPTIONS = load_assets()


# --- 3. Preprocessing and Prediction Function ---
def preprocess_and_predict(input_df, scaler_obj, reg_model_obj, clf_model_obj, le_map_obj):
    """Applies preprocessing (LE, Scaling) and runs predictions."""

    # 3.1 Apply Label Encoding
    for col in CATEGORICAL_COLS:
        # Map string input to the integer label used in training (e.g., 'Site A' -> 0)
        input_df[col] = input_df[col].map(le_map_obj.get(col))
        # Handle case where a category might be missing (shouldn't happen with select boxes)
        if input_df[col].isnull().any():
            raise ValueError(f"Missing label encoding for a value in {col}. Check LE_MAP.json.")

    # 3.2 Apply Scaling to Numerical Columns
    df_to_scale = input_df[NUMERIC_COLS].copy()
    input_df[NUMERIC_COLS] = scaler_obj.transform(df_to_scale)

    # 3.3 Re-order features to match the model's training order (CRUCIAL)
    final_features = input_df[FEATURE_COLS].values

    # 3.4 Make Predictions
    reg_prediction = reg_model_obj.predict(final_features)[0]
    clf_label = clf_model_obj.predict(final_features)[0]

    # 3.5 Reverse Label Encoding for Classification label (0=Low, 1=Medium, 2=High assumed)
    efficiency_classes = {0: 'Low (< 85%)', 1: 'Medium (85% to < 95%)', 2: 'High (>= 95%)'}
    clf_prediction = efficiency_classes.get(clf_label, 'Unknown')

    return reg_prediction, clf_prediction

def categorize_efficiency(efficiency):
    """Replicates the categorization logic for the regression result."""
    if efficiency >= 95:
        return 'High Efficiency (>= 95%)'
    elif efficiency >= 85:
        return 'Medium Efficiency (85% to < 95%)'
    else:
        return 'Low Efficiency (< 85%)'


# --- 4. Streamlit App Layout ---

st.set_page_config(page_title="Bioremediation Efficiency Predictor", layout="wide")

st.title("ðŸ§ª Bioremediation Efficiency Prediction App")
st.markdown("Predict the **Heavy Metal Removal Efficiency (%)** based on experimental and environmental parameters using your trained models.")

st.divider()

# --- User Input Fields ---

with st.sidebar:
    st.header("1. Environmental & Site Inputs")

    # Use the options derived from the loaded LE_MAP
    site = st.selectbox("Site Location", options=CAT_OPTIONS['Site'])
    metal = st.selectbox("Metal Being Removed", options=CAT_OPTIONS['Metal'])
    microbe = st.selectbox("Microbe Used", options=CAT_OPTIONS['Microbe_Used'])
    source = st.selectbox("Water/Soil Source", options=CAT_OPTIONS['Source'])

    st.header("2. Location Data")
    latitude = st.number_input("Latitude", min_value=25.0, max_value=26.0, value=25.44, step=0.01)
    longitude = st.number_input("Longitude", min_value=81.0, max_value=82.5, value=81.85, step=0.01)

st.header("3. Experimental Parameters")

# Main area for Numerical Inputs
col1, col2, col3 = st.columns(3)

with col1:
    initial_ph = st.number_input("Initial pH", min_value=4.0, max_value=10.0, value=6.5, step=0.1)
    temperature = st.number_input("Temperature (Â°C)", min_value=20.0, max_value=45.0, value=30.0, step=0.1)

with col2:
    concentration = st.number_input("Initial Metal Concentration (mg/L)", min_value=10.0, max_value=150.0, value=50.0, step=1.0)
    contact_time = st.slider("Contact Time (hours)", min_value=12, max_value=36, value=24)

with col3:
    microbe_dose = st.number_input("Microbe Dose (mg/L)", min_value=50.0, max_value=500.0, value=250.0, step=10.0)

# --- Prediction Button and Output ---

if st.button("Predict Efficiency", type="primary"):

    # Create a single-row DataFrame from user inputs
    input_data = pd.DataFrame([{
        'Site': site,
        'Metal': metal,
        'Microbe_Used': microbe,
        'Source': source,
        'Initial_pH': initial_ph,
        'Temperature_C': temperature,
        'Concentration_mg_L': concentration,
        'Contact_Time_hours': contact_time,
        'Microbe_Dose_mg_L': microbe_dose,
        'Latitude': latitude,
        'Longitude': longitude
    }])

    with st.spinner("Processing data and generating prediction..."):
        try:
            # Run prediction
            reg_pred, clf_pred = preprocess_and_predict(input_data, scaler, reg_model, clf_model, LE_MAP)

            st.divider()
            st.subheader("âœ… Prediction Results")

            col_reg, col_clf = st.columns(2)

            # Regression Output
            with col_reg:
                st.metric(
                    label="Predicted Removal Efficiency (Regression)",
                    value=f"{reg_pred:.2f} %",
                    delta=f"Category: {categorize_efficiency(reg_pred)}"
                )
                st.caption("This is the exact percentage predicted by the Random Forest Regressor model.")

            # Classification Output
            with col_clf:
                if 'High' in clf_pred:
                    badge_color = 'green'
                elif 'Medium' in clf_pred:
                    badge_color = 'orange'
                else:
                    badge_color = 'red'

                st.markdown(
                    f"**Predicted Efficiency Category (Classification):** <span style='background-color:{badge_color}; color:white; padding: 5px 10px; border-radius: 5px; font-weight: bold;'>{clf_pred}</span>",
                    unsafe_allow_html=True
                )
                st.caption("This is the category (High/Medium/Low) predicted by the Random Forest Classifier model.")

        except Exception as e:
            st.error(f"An error occurred during prediction. Check console logs and your file dependencies.")
            st.code(str(e), language='text')

# Add necessary deployment instructions in the sidebar
st.sidebar.markdown("""
---
**Deployment Checklist**
1.  **5 Files** must be in your repository: `app.py`, `requirements.txt`, `LE_MAP.json`, `scaler.pkl`, `rf_regressor_model.pkl`, `rf_classifier_model.pkl`.
2.  Deploy via Streamlit Community Cloud (share.streamlit.io).
""")